"""
ReccoBeats API int√©gr√© avec scraper Spotify ID + Selenium
Solution compl√®te : Nom artiste + titre ‚Üí ID Spotify ‚Üí Features ReccoBeats
Version avec navigateur visible pour debug
"""
import requests
import json
import time
import logging
import re
import urllib.parse
import random
from typing import Dict, List, Optional
from bs4 import BeautifulSoup

# Imports Selenium
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, WebDriverException

logger = logging.getLogger('ReccoBeatsIntegrated')

class ReccoBeatsIntegratedClient:
    """Client ReccoBeats avec scraper Spotify ID int√©gr√© + Selenium"""
    
    def __init__(self, cache_file: str = "reccobeats_integrated_cache.json"):
        self.cache_file = cache_file
        self.cache = self._load_cache()
        
        # Configuration ReccoBeats
        self.recco_base_url = "https://api.reccobeats.com/v1"
        self.recco_session = requests.Session()
        self.recco_session.headers.update({
            'Accept': 'application/json',
            'User-Agent': 'ReccoBeats-Python-Client/3.0'
        })
        
        # Configuration Scraper classique
        self.scraper_session = requests.Session()
        self.scraper_session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # Configuration Selenium
        self.driver = None
        self.use_selenium = True  # Activer/d√©sactiver Selenium
        
        # Patterns pour extraire les IDs Spotify
        self.spotify_id_patterns = [
            r'open\.spotify\.com/(?:intl-[a-z]{2}/)?track/([a-zA-Z0-9]{22})',
            r'spotify:track:([a-zA-Z0-9]{22})',
        ]
        
        logger.info("ReccoBeats client int√©gr√© initialis√© avec Selenium")

    def _load_cache(self) -> Dict:
        """Charge le cache depuis le fichier"""
        try:
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            return {}

    def _save_cache(self):
        """Sauvegarde le cache"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Erreur sauvegarde cache: {e}")

    def _get_cache_key(self, artist: str, title: str) -> str:
        return f"{artist.lower().strip()}::{title.lower().strip()}"

    def extract_spotify_id_from_url(self, url: str) -> Optional[str]:
        """Extrait l'ID Spotify depuis une URL"""
        for pattern in self.spotify_id_patterns:
            match = re.search(pattern, url)
            if match:
                spotify_id = match.group(1)
                if len(spotify_id) == 22 and spotify_id.replace('_', '').replace('-', '').isalnum():
                    return spotify_id
        return None

    # ========== M√âTHODES SELENIUM ==========

    def _init_selenium_driver(self):
        """Initialise le driver Selenium avec navigateur visible"""
        if self.driver:
            return  # D√©j√† initialis√©
        
        print("üåê Initialisation du navigateur Selenium...")
        
        try:
            # Configuration Chrome
            chrome_options = Options()
            
            # MODE VISIBLE (pour voir ce qui se passe)
            # chrome_options.add_argument("--headless")  # Comment√© pour voir le navigateur
            
            # Options pour √©viter la d√©tection
            chrome_options.add_argument("--disable-blink-features=AutomationControlled")
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            chrome_options.add_argument("--disable-extensions")
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            
            # User-Agent r√©aliste
            chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
            
            self.driver = webdriver.Chrome(options=chrome_options)
            
            # Script pour masquer les signes d'automation
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
            print("‚úÖ Navigateur Chrome initialis√© (mode visible)")
            
        except Exception as e:
            print(f"‚ùå Erreur initialisation Selenium: {e}")
            print("üí° Assurez-vous d'avoir Chrome et ChromeDriver install√©s")
            self.driver = None

    def _close_selenium_driver(self):
        """Ferme le driver Selenium"""
        if self.driver:
            self.driver.quit()
            self.driver = None
            print("üîí Navigateur ferm√©")

    def _search_google_selenium(self, artist: str, title: str) -> Optional[str]:
        """Recherche Google avec Selenium (navigateur visible)"""
        print(f"\nüîç === RECHERCHE GOOGLE SELENIUM ===")
        print(f"Artiste: {artist}")
        print(f"Titre: {title}")
        
        try:
            if not self.driver:
                self._init_selenium_driver()
            
            if not self.driver:
                print("‚ùå Driver Selenium non disponible")
                return None
            
            # Construire la requ√™te
            query = f'"{artist}" "{title}" site:open.spotify.com'
            google_url = f"https://www.google.com/search?q={urllib.parse.quote_plus(query)}"
            
            print(f"üìù Requ√™te: {query}")
            print(f"üîó URL: {google_url}")
            print(f"üåê Ouverture dans le navigateur...")
            
            # Naviguer vers Google
            self.driver.get(google_url)
            
            # Attendre que la page se charge
            print(f"‚è≥ Attente du chargement...")
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # V√©rifier le titre de la page
            page_title = self.driver.title
            print(f"üìÑ Titre de la page: {page_title}")
            
            # V√©rifier s'il y a un CAPTCHA ou blocage
            page_source = self.driver.page_source.lower()
            blocking_signs = ['captcha', 'unusual traffic', 'verify you are human', 'blocked']
            detected_blocks = [sign for sign in blocking_signs if sign in page_source]
            
            if detected_blocks:
                print(f"üö´ Signes de blocage d√©tect√©s: {detected_blocks}")
                print(f"üëÄ REGARDEZ LE NAVIGATEUR - Il pourrait y avoir un CAPTCHA √† r√©soudre")
                
                # Demander √† l'utilisateur de r√©soudre manuellement
                input("üîß R√©solvez manuellement le probl√®me dans le navigateur puis appuyez sur Entr√©e...")
            
            # Chercher les liens Spotify
            print(f"üîç Recherche des liens Spotify...")
            
            # M√©thode 1: Par s√©lecteur CSS
            spotify_links = []
            try:
                link_elements = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='open.spotify.com']")
                spotify_links = [elem.get_attribute('href') for elem in link_elements if elem.get_attribute('href')]
                print(f"üéµ Liens Spotify trouv√©s (CSS): {len(spotify_links)}")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur recherche CSS: {e}")
            
            # M√©thode 2: Par XPath si CSS √©choue
            if not spotify_links:
                try:
                    link_elements = self.driver.find_elements(By.XPATH, "//a[contains(@href, 'open.spotify.com')]")
                    spotify_links = [elem.get_attribute('href') for elem in link_elements if elem.get_attribute('href')]
                    print(f"üéµ Liens Spotify trouv√©s (XPath): {len(spotify_links)}")
                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur recherche XPath: {e}")
            
            # Afficher et traiter les liens trouv√©s
            if spotify_links:
                print(f"üìã Liens Spotify d√©tect√©s:")
                for i, link in enumerate(spotify_links[:5]):
                    print(f"   {i+1}. {link}")
                    
                    # Extraire l'ID
                    spotify_id = self.extract_spotify_id_from_url(link)
                    if spotify_id:
                        print(f"      ‚úÖ ID extrait: {spotify_id}")
                        print(f"üéØ SUCC√àS GOOGLE SELENIUM!")
                        return spotify_id
                    else:
                        print(f"      ‚ùå Pas d'ID extractible")
                
                print(f"üòû Aucun ID valide dans les liens trouv√©s")
            else:
                print(f"üòû Aucun lien Spotify trouv√©")
                print(f"üëÄ REGARDEZ LE NAVIGATEUR - Y a-t-il des r√©sultats visibles ?")
                
                # Option : laisser l'utilisateur copier manuellement
                manual_url = input("üîß Si vous voyez un lien Spotify, copiez-le ici (ou Entr√©e pour continuer): ").strip()
                if manual_url and 'open.spotify.com' in manual_url:
                    spotify_id = self.extract_spotify_id_from_url(manual_url)
                    if spotify_id:
                        print(f"‚úÖ ID extrait manuellement: {spotify_id}")
                        return spotify_id
            
        except TimeoutException:
            print(f"‚è∞ Timeout Selenium")
        except WebDriverException as e:
            print(f"üåê Erreur WebDriver: {e}")
        except Exception as e:
            print(f"üí• Erreur inattendue Selenium: {e}")
        
        print(f"‚ùå √âCHEC GOOGLE SELENIUM")
        return None

    # ========== M√âTHODES SCRAPING CLASSIQUE ==========

    def _search_google(self, artist: str, title: str) -> Optional[str]:
        """Recherche sur Google avec logs visuels d√©taill√©s"""
        print(f"\nüîç === RECHERCHE GOOGLE CLASSIQUE ===")
        print(f"Artiste: {artist}")
        print(f"Titre: {title}")
        
        try:
            # D√©lai al√©atoire
            delay = random.uniform(3, 7)
            print(f"‚è±Ô∏è  D√©lai anti-d√©tection: {delay:.1f}s")
            time.sleep(delay)
            
            # User-Agent al√©atoire
            user_agents = [
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/120.0.0.0 Safari/537.36'
            ]
            selected_ua = random.choice(user_agents)
            self.scraper_session.headers['User-Agent'] = selected_ua
            print(f"ü§ñ User-Agent: {selected_ua[:60]}...")
            
            # Construction de la requ√™te
            query = f'"{artist}" "{title}" site:open.spotify.com'
            encoded_query = urllib.parse.quote_plus(query)
            google_url = f"https://www.google.com/search?q={encoded_query}"
            
            print(f"üìù Requ√™te: {query}")
            print(f"üîó URL: {google_url}")
            print(f"üì° Envoi de la requ√™te...")
            
            response = self.scraper_session.get(google_url, timeout=15)
            
            print(f"üìä Status HTTP: {response.status_code}")
            print(f"üìè Taille r√©ponse: {len(response.text)} caract√®res")
            
            if response.status_code == 200:
                # Analyser le contenu HTML
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # V√©rifier s'il y a des signes de blocage
                page_text = response.text.lower()
                blocking_signs = [
                    'unusual traffic', 'captcha', 'blocked', 'robot', 'automation',
                    'verify you are human', 'suspicious activity', 'temporary error'
                ]
                
                detected_blocks = [sign for sign in blocking_signs if sign in page_text]
                if detected_blocks:
                    print(f"üö´ Signes de blocage d√©tect√©s: {detected_blocks}")
                
                # Chercher les liens
                all_links = soup.find_all('a', href=True)
                print(f"üîó Total liens trouv√©s: {len(all_links)}")
                
                spotify_links = []
                
                for link in all_links:
                    href = link.get('href', '')
                    
                    if 'open.spotify.com' in href:
                        spotify_links.append(href)
                
                print(f"üéµ Liens Spotify trouv√©s: {len(spotify_links)}")
                
                if spotify_links:
                    print(f"üìã Liens Spotify d√©tect√©s:")
                    for i, link in enumerate(spotify_links[:5]):  # Afficher max 5
                        print(f"   {i+1}. {link}")
                        
                        # Nettoyer l'URL Google
                        if link.startswith('/url?q='):
                            actual_url = urllib.parse.unquote(link.split('/url?q=')[1].split('&')[0])
                            print(f"      ‚Üí Nettoy√©e: {actual_url}")
                        else:
                            actual_url = link
                        
                        # Tenter d'extraire l'ID
                        spotify_id = self.extract_spotify_id_from_url(actual_url)
                        if spotify_id:
                            print(f"      ‚úÖ ID extrait: {spotify_id}")
                            print(f"üéØ SUCC√àS GOOGLE!")
                            return spotify_id
                        else:
                            print(f"      ‚ùå Pas d'ID extractible")
                    
                    print(f"üòû Aucun ID valide trouv√© dans les liens Spotify")
                else:
                    print(f"üòû Aucun lien Spotify trouv√©")
                    
            elif response.status_code == 429:
                print(f"üö´ Rate limit Google (429)")
            else:
                print(f"‚ùå Erreur HTTP {response.status_code}")
                
        except requests.exceptions.Timeout:
            print(f"‚è∞ Timeout Google")
        except requests.exceptions.RequestException as e:
            print(f"üåê Erreur r√©seau Google: {e}")
        except Exception as e:
            print(f"üí• Erreur inattendue Google: {e}")
        
        print(f"‚ùå √âCHEC GOOGLE")
        return None

    def _search_duckduckgo(self, artist: str, title: str) -> Optional[str]:
        """Recherche sur DuckDuckGo avec logs visuels d√©taill√©s"""
        print(f"\nü¶Ü === RECHERCHE DUCKDUCKGO ===")
        print(f"Artiste: {artist}")
        print(f"Titre: {title}")
        
        try:
            # D√©lai plus court pour DDG
            delay = random.uniform(2, 4)
            print(f"‚è±Ô∏è  D√©lai: {delay:.1f}s")
            time.sleep(delay)
            
            # User-Agent
            user_agents = [
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            ]
            selected_ua = random.choice(user_agents)
            self.scraper_session.headers['User-Agent'] = selected_ua
            print(f"ü§ñ User-Agent: {selected_ua[:60]}...")
            
            query = f'"{artist}" "{title}" site:open.spotify.com'
            encoded_query = urllib.parse.quote_plus(query)
            ddg_url = f"https://html.duckduckgo.com/html/?q={encoded_query}"
            
            print(f"üìù Requ√™te: {query}")
            print(f"üîó URL: {ddg_url}")
            print(f"üì° Envoi de la requ√™te DDG...")
            
            response = self.scraper_session.get(ddg_url, timeout=15)
            
            print(f"üìä Status HTTP: {response.status_code}")
            print(f"üìè Taille r√©ponse: {len(response.text)} caract√®res")
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Analyser les liens DDG
                all_links = soup.find_all('a', href=True)
                print(f"üîó Total liens DDG: {len(all_links)}")
                
                spotify_links = []
                for link in all_links:
                    href = link.get('href', '')
                    if 'open.spotify.com' in href:
                        spotify_links.append(href)
                
                print(f"üéµ Liens Spotify DDG: {len(spotify_links)}")
                
                if spotify_links:
                    print(f"üìã Liens Spotify DDG:")
                    for i, link in enumerate(spotify_links[:3]):
                        print(f"   {i+1}. {link}")
                        
                        spotify_id = self.extract_spotify_id_from_url(link)
                        if spotify_id:
                            print(f"      ‚úÖ ID extrait: {spotify_id}")
                            print(f"üéØ SUCC√àS DUCKDUCKGO!")
                            return spotify_id
                        else:
                            print(f"      ‚ùå Pas d'ID extractible")
                else:
                    print(f"üòû Aucun lien Spotify DDG")
                    
            elif response.status_code == 202:
                print(f"‚è≥ DDG Status 202 (traitement en cours)")
            else:
                print(f"‚ùå Erreur DDG {response.status_code}")
                
        except Exception as e:
            print(f"üí• Erreur DDG: {e}")
        
        print(f"‚ùå √âCHEC DUCKDUCKGO")
        return None

    # ========== M√âTHODE FALLBACK MANUEL ==========

    def get_spotify_id_manual(self, artist: str, title: str) -> Optional[str]:
        """Demande l'ID Spotify manuellement √† l'utilisateur"""
        print(f"\nüîç Recherche manuelle n√©cessaire:")
        print(f"   Artiste: {artist}")
        print(f"   Titre: {title}")
        
        search_url = f"https://open.spotify.com/search/{urllib.parse.quote(f'{artist} {title}')}"
        print(f"üì± Ouvrez: {search_url}")
        print(f"üí° Cliquez sur le bon morceau et copiez l'URL compl√®te")
        
        spotify_url = input("Collez l'URL Spotify (ou Entr√©e pour passer): ").strip()
        
        if spotify_url and 'open.spotify.com' in spotify_url:
            extracted_id = self.extract_spotify_id_from_url(spotify_url)
            if extracted_id:
                print(f"‚úÖ ID extrait: {extracted_id}")
                return extracted_id
            else:
                print("‚ùå Impossible d'extraire l'ID de cette URL")
        
        return None

    # ========== M√âTHODE PRINCIPALE DE RECHERCHE ==========

    def search_spotify_id_via_web(self, artist: str, title: str, allow_manual: bool = True) -> Optional[str]:
        """Recherche avec Selenium en priorit√© puis fallback classique"""
        print(f"\n" + "="*60)
        print(f"üöÄ D√âBUT RECHERCHE SPOTIFY ID")
        print(f"üé§ Artiste: {artist}")
        print(f"üéµ Titre: {title}")
        print(f"="*60)
        
        if self.use_selenium:
            print(f"\nüöÄ RECHERCHE AVEC SELENIUM (NAVIGATEUR VISIBLE)")
            
            # Tentative Selenium Google
            spotify_id = self._search_google_selenium(artist, title)
            
            if spotify_id:
                self._close_selenium_driver()  # Fermer le navigateur apr√®s succ√®s
                print(f"\nüéâ SUCC√àS SELENIUM! ID: {spotify_id}")
                print(f"="*60)
                return spotify_id
            
            # Si Selenium √©choue, proposer de continuer ou passer aux m√©thodes classiques
            print(f"\nü§î Selenium a √©chou√©. Options:")
            print(f"1. Essayer les m√©thodes classiques (requests)")
            print(f"2. Recherche manuelle")
            print(f"3. Passer ce morceau")
            
            choice = input("Choix (1/2/3): ").strip()
            
            if choice == "1":
                print(f"üîÑ Basculement vers m√©thodes classiques...")
                self._close_selenium_driver()
                # Continuer avec les m√©thodes classiques ci-dessous
            elif choice == "2":
                if allow_manual:
                    spotify_id = self.get_spotify_id_manual(artist, title)
                    self._close_selenium_driver()
                    if spotify_id:
                        print(f"\nüéâ SUCC√àS MANUEL! ID: {spotify_id}")
                    print(f"="*60)
                    return spotify_id
            else:
                self._close_selenium_driver()
                print(f"\nüíî ABANDONN√â par l'utilisateur")
                print(f"="*60)
                return None
        
        # M√©thodes classiques (requests) si Selenium d√©sactiv√© ou a √©chou√©
        print(f"\nüîÑ Recherche classique (requests)...")
        
        # Tentative Google classique
        spotify_id = self._search_google(artist, title)
        
        # Tentative DuckDuckGo si Google √©choue
        if not spotify_id:
            spotify_id = self._search_duckduckgo(artist, title)
        
        # Fallback manuel si tout √©choue
        if not spotify_id and allow_manual:
            print(f"\n" + "‚ö†Ô∏è "*20)
            print(f"üí• TOUTES LES RECHERCHES AUTOMATIQUES ONT √âCHOU√â")
            print(f"‚ö†Ô∏è "*20)
            
            response = input(f"\nRecherche manuelle pour '{artist} - {title}' ? (o/n): ").strip().lower()
            
            if response in ['o', 'oui', 'y', 'yes']:
                spotify_id = self.get_spotify_id_manual(artist, title)
        
        # R√©sultat final
        if spotify_id:
            print(f"\nüéâ SUCC√àS! ID trouv√©: {spotify_id}")
        else:
            print(f"\nüíî √âCHEC TOTAL pour '{artist} - {title}'")
        
        print(f"="*60)
        return spotify_id

    # ========== M√âTHODES RECCOBEATS API ==========

    def get_track_from_reccobeats(self, spotify_id: str) -> Optional[Dict]:
        """R√©cup√®re les donn√©es d'un track depuis ReccoBeats via son ID Spotify"""
        try:
            url = f"{self.recco_base_url}/track"
            params = {'ids': spotify_id}
            
            response = self.recco_session.get(url, params=params, timeout=15)
            logger.debug(f"ReccoBeats response status: {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                logger.debug(f"ReccoBeats response: {json.dumps(data, indent=2)[:200]}...")
                
                # Traiter la r√©ponse ReccoBeats avec structure {"content": [...]}
                if isinstance(data, dict) and 'content' in data:
                    # Structure : {"content": [track_data]}
                    content = data['content']
                    if isinstance(content, list) and len(content) > 0:
                        track_data = content[0]
                    else:
                        logger.warning("Contenu vide dans la r√©ponse ReccoBeats")
                        return None
                elif isinstance(data, list) and len(data) > 0:
                    track_data = data[0]
                elif isinstance(data, dict):
                    track_data = data
                else:
                    logger.warning("Format de r√©ponse ReccoBeats inattendu")
                    return None
                
                logger.debug("‚úÖ Donn√©es track r√©cup√©r√©es depuis ReccoBeats")
                return track_data
                
            elif response.status_code == 404:
                logger.warning(f"Track non trouv√© dans ReccoBeats: {spotify_id}")
            else:
                logger.error(f"Erreur ReccoBeats: {response.status_code} - {response.text}")
                
        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration ReccoBeats: {e}")
        
        return None

    def get_track_audio_features(self, reccobeats_id: str) -> Optional[Dict]:
        """R√©cup√®re les audio features d'un track via son ID ReccoBeats"""
        try:
            url = f"{self.recco_base_url}/track/{reccobeats_id}/audio-features"
            
            response = self.recco_session.get(url, timeout=15)
            
            if response.status_code == 200:
                features = response.json()
                logger.debug("‚úÖ Audio features r√©cup√©r√©es")
                return features
            elif response.status_code == 404:
                logger.warning(f"Audio features non trouv√©es pour: {reccobeats_id}")
            else:
                logger.error(f"Erreur audio features: {response.status_code}")
                
        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration audio features: {e}")
        
        return None

    def search_track_complete(self, artist: str, title: str) -> Optional[Dict]:
        """
        Recherche compl√®te : artiste + titre ‚Üí ID Spotify ‚Üí donn√©es ReccoBeats
        """
        logger.info(f"Recherche compl√®te: '{artist}' - '{title}'")
        
        # V√©rifier le cache
        cache_key = self._get_cache_key(artist, title)
        if cache_key in self.cache:
            cached_data = self.cache[cache_key]
            if 'error' not in cached_data:
                logger.debug("Donn√©es trouv√©es en cache")
                return cached_data
        
        # √âtape 1: Rechercher l'ID Spotify
        logger.debug("üîç Recherche ID Spotify...")
        spotify_id = self.search_spotify_id_via_web(artist, title)
        
        if not spotify_id:
            logger.warning("‚ùå Aucun ID Spotify trouv√©")
            self.cache[cache_key] = {'error': 'spotify_id_not_found'}
            self._save_cache()
            return None
        
        logger.info(f"‚úÖ ID Spotify trouv√©: {spotify_id}")
        
        # √âtape 2: R√©cup√©rer les donn√©es ReccoBeats
        logger.debug("üîç R√©cup√©ration donn√©es ReccoBeats...")
        track_data = self.get_track_from_reccobeats(spotify_id)
        
        if not track_data:
            logger.warning("‚ùå Donn√©es track non trouv√©es dans ReccoBeats")
            self.cache[cache_key] = {'error': 'reccobeats_not_found', 'spotify_id': spotify_id}
            self._save_cache()
            return None
        
        # √âtape 3: Enrichir avec audio features si possible
        reccobeats_id = track_data.get('id')
        if reccobeats_id:
            logger.debug("üîç R√©cup√©ration audio features...")
            audio_features = self.get_track_audio_features(reccobeats_id)
            if audio_features:
                track_data['audio_features'] = audio_features
                logger.debug("‚úÖ Audio features ajout√©es")
        
        # Enrichir les m√©tadonn√©es
        enriched_data = {
            'search_artist': artist,
            'search_title': title,
            'spotify_id': spotify_id,
            'source': 'reccobeats_integrated',
            'success': True,
            **track_data
        }
        
        # Extraire le BPM si disponible
        if 'audio_features' in enriched_data:
            features = enriched_data['audio_features']
            if 'tempo' in features:
                enriched_data['bpm'] = int(round(features['tempo']))
        
        # Mettre en cache
        self.cache[cache_key] = enriched_data
        self._save_cache()
        
        logger.info(f"‚úÖ Succ√®s complet pour '{title}'")
        return enriched_data

    def fetch_discography(self, artist: str, track_titles: List[str]) -> List[Dict]:
        """
        R√©cup√®re les donn√©es pour une discographie compl√®te
        """
        logger.info(f"=== FETCH DISCOGRAPHY INT√âGR√â ===")
        logger.info(f"Artiste: '{artist}'")
        logger.info(f"Titres: {len(track_titles)} morceaux")
        
        results = []
        
        for i, title in enumerate(track_titles):
            logger.debug(f"Traitement {i+1}/{len(track_titles)}: '{title}'")
            
            track_data = self.search_track_complete(artist, title)
            
            if track_data and track_data.get('success'):
                # Succ√®s
                result = {
                    'artist': artist,
                    'title': title,
                    **track_data
                }
            else:
                # √âchec
                result = {
                    'artist': artist,
                    'title': title,
                    'success': False,
                    'error': track_data.get('error', 'unknown_error') if track_data else 'search_failed',
                    'source': 'reccobeats_integrated'
                }
            
            results.append(result)
            
            # Rate limiting respectueux (important pour le scraping)
            if i < len(track_titles) - 1:
                time.sleep(4)  # 4 secondes entre chaque track
        
        success_count = len([r for r in results if r.get('success')])
        logger.info(f"=== R√âSULTATS FINAUX ===")
        logger.info(f"Succ√®s: {success_count}/{len(track_titles)}")
        
        return results

    # ========== M√âTHODES UTILITAIRES ==========

    def test_connection(self) -> Dict[str, bool]:
        """Teste les connexions"""
        results = {}
        
        # Test scraper avec un exemple connu
        test_id = self.extract_spotify_id_from_url("https://open.spotify.com/track/4EVMhVr6GslvST0uLx8VIJ")
        results['spotify_id_extraction'] = test_id == "4EVMhVr6GslvST0uLx8VIJ"
        
        # Test ReccoBeats avec un ID Spotify connu
        try:
            test_data = self.get_track_from_reccobeats("4EVMhVr6GslvST0uLx8VIJ")  # "Shape of You"
            results['reccobeats_api'] = test_data is not None
        except:
            results['reccobeats_api'] = False
        
        # Test Selenium
        try:
            self._init_selenium_driver()
            results['selenium'] = self.driver is not None
            self._close_selenium_driver()
        except:
            results['selenium'] = False
        
        logger.info(f"Tests de connexion: {results}")
        return results

    def clear_cache(self):
        """Vide le cache"""
        self.cache.clear()
        self._save_cache()
        logger.info("Cache vid√©")

    def get_cache_stats(self) -> Dict:
        """Statistiques du cache"""
        total = len(self.cache)
        errors = len([v for v in self.cache.values() if isinstance(v, dict) and 'error' in v])
        success = total - errors
        
        return {
            'total_entries': total,
            'successful_entries': success,
            'error_entries': errors,
            'cache_file': self.cache_file
        }

    def close(self):
        """Ferme toutes les connexions"""
        self._close_selenium_driver()
        logger.info("Connexions ferm√©es")
        self.scraper_session.close()