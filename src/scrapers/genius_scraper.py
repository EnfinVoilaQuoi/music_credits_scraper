"""Scraper pour r√©cup√©rer les cr√©dits complets sur Genius - Version corrig√©e"""
import time
import re
import subprocess
from typing import List, Dict, Any, Optional
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

from src.config import SELENIUM_TIMEOUT, DELAY_BETWEEN_REQUESTS
from src.models import Track, Credit, CreditRole
from src.utils.logger import get_logger, log_error


logger = get_logger(__name__)


class GeniusScraper:
    """Scraper pour extraire les cr√©dits complets depuis Genius"""
    
    def __init__(self, headless: bool = True):
        self.headless = headless
        self.driver = None
        self._init_driver()
    
    def _init_driver(self):
        """Initialise le driver Selenium"""
        try:
            options = Options()
            if self.headless:
                options.add_argument('--headless=new')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            options.add_argument('--window-size=1920,1080')
            options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
            
            # Options pour r√©duire les messages d'erreur
            options.add_argument('--log-level=3')
            options.add_argument('--disable-logging')
            options.add_argument('--silent')
            options.add_experimental_option('excludeSwitches', ['enable-logging'])
            options.add_experimental_option('useAutomationExtension', False)
            
            # D√©sactiver les fonctionnalit√©s inutiles
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_argument('--disable-features=VizDisplayCompositor')
            options.add_argument('--disable-background-networking')
            
            # D√©sactiver les images pour acc√©l√©rer
            prefs = {
                "profile.managed_default_content_settings.images": 2,
                "profile.default_content_setting_values.notifications": 2,
                "profile.default_content_settings.popups": 0
            }
            options.add_experimental_option("prefs", prefs)

            # Masquer les messages WebGL et GPU
            options.add_argument('--disable-web-security')
            options.add_argument('--disable-features=VizDisplayCompositor')
            options.add_argument('--disable-software-rasterizer')
            options.add_argument('--disable-background-timer-throttling')
            options.add_argument('--disable-renderer-backgrounding')
            options.add_argument('--disable-backgrounding-occluded-windows')
            options.add_argument('--disable-ipc-flooding-protection')
            
            # Masquer sp√©cifiquement les messages WebGL
            options.add_experimental_option('excludeSwitches', ['enable-logging'])
            options.add_experimental_option('useAutomationExtension', False)
            
            # Logs seulement pour les erreurs critiques
            options.add_argument('--log-level=3')
            options.add_argument('--silent')
            
            # D√©sactiver WebGL compl√®tement si pas n√©cessaire
            options.add_argument('--disable-webgl')
            options.add_argument('--disable-webgl2')
            
            # Essayer d'abord le driver local
            from pathlib import Path
            local_driver = Path(__file__).parent.parent.parent / "drivers" / "chromedriver.exe"
            
            if not local_driver.exists():
                for path in (Path(__file__).parent.parent.parent / "drivers").rglob("chromedriver.exe"):
                    local_driver = path
                    break
            
            if local_driver.exists():
                logger.info(f"Utilisation du ChromeDriver local: {local_driver}")
                service = ChromeService(str(local_driver))
            else:
                logger.info("ChromeDriver local non trouv√©, utilisation de webdriver-manager")
                service = ChromeService(ChromeDriverManager().install())
            
            service.log_output = subprocess.DEVNULL
            
            self.driver = webdriver.Chrome(service=service, options=options)
            self.wait = WebDriverWait(self.driver, SELENIUM_TIMEOUT)
            
            logger.info("Driver Selenium initialis√© avec succ√®s")
            
        except Exception as e:
            logger.error(f"Erreur lors de l'initialisation du driver: {e}")
            raise
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()
    
    def close(self):
        """Ferme le driver"""
        if self.driver:
            self.driver.quit()
            logger.info("Driver Selenium ferm√©")
    
    def scrape_track_credits(self, track: Track) -> List[Credit]:
        """Scrape les cr√©dits complets d'un morceau - VERSION CORRIG√âE"""
        if not track.genius_url:
            logger.warning(f"Pas d'URL Genius pour {track.title}")
            return []
    
        credits = []
    
        try:
            logger.info(f"Scraping des cr√©dits pour: {track.title}")
            self.driver.get(track.genius_url)

            logger.debug(f"URL visit√©e : {self.driver.current_url}")

            # Gestion des cookies
            try:
                WebDriverWait(self.driver, 5).until(
                    EC.presence_of_element_located((By.ID, "onetrust-banner-sdk"))
                )
                accept_btn = WebDriverWait(self.driver, 5).until(
                    EC.element_to_be_clickable((By.ID, "onetrust-accept-btn-handler"))
                )
                accept_btn.click()
                logger.debug("‚úÖ Cookies accept√©s")
                time.sleep(1)
            except TimeoutException:
                logger.debug("‚ö†Ô∏è Pas de banni√®re cookies")

            # NOUVEAU: Extraire d'abord les m√©tadonn√©es du header (album, num√©ro de piste)
            self._extract_header_metadata(track)

            # Aller √† la section "Credits"
            credits_header = WebDriverWait(self.driver, 5).until(
                EC.presence_of_element_located((By.XPATH, "//div[contains(@class, 'SongInfo__Title') and text()='Credits']"))
            )
            if not credits_header:
                logger.error("‚ùå Aucun header Credits trouv√©")
                return credits
            self.driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", credits_header)
            time.sleep(2)

            # Bouton "Expand"
            expand_button = self._find_expand_button()
            if expand_button:
                try:
                    button_text = expand_button.text.strip()
                    button_location = expand_button.location
                    logger.debug(f"üìç Bouton s√©lectionn√©: '{button_text}' √† position {button_location}")
                    
                    self.driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", expand_button)
                    time.sleep(1)
                
                    self.driver.execute_script("arguments[0].click();", expand_button)
                    logger.debug("Bouton Expand cliqu√©")
                
                    # Attendre que le contenu √©tendu soit visible
                    try:
                        WebDriverWait(self.driver, 10).until(
                            lambda driver: len(driver.find_elements(By.CSS_SELECTOR, "div[class*='SongInfo__Credit']")) > 0
                        )
                        time.sleep(2)
                    except TimeoutException:
                        logger.warning("Timeout en attendant le contenu √©tendu")
                except Exception as e:
                    logger.error(f"Erreur lors du clic sur le bouton Expand: {e}")
            else:
                logger.debug("Aucun bouton Expand trouv√©")

            # ‚úÖ CORRECTION : Extraire les cr√©dits avec la bonne signature de m√©thode
            credits = self._extract_credits(track)

            # Mettre √† jour le track
            track.last_scraped = datetime.now()
            for credit in credits:
                track.add_credit(credit)

            logger.info(f"{len(credits)} cr√©dits extraits pour {track.title}")

        except TimeoutException:
            error_msg = f"Timeout lors du scraping de {track.title}"
            logger.error(error_msg)
            track.scraping_errors.append(error_msg)
            log_error(track.title, error_msg, "genius_scraper")

        except Exception as e:
            error_msg = f"Erreur lors du scraping: {str(e)}"
            logger.error(f"{error_msg} pour {track.title}")
            track.scraping_errors.append(error_msg)
            log_error(track.title, error_msg, "genius_scraper")

        # Respecter le rate limit
        time.sleep(DELAY_BETWEEN_REQUESTS)

        return credits
    
    def _find_expand_button(self) -> Optional[Any]:
        """Trouve le bouton Expand sp√©cifiquement dans la section Credits"""
        try:
            logger.debug("Recherche de tous les boutons Expand...")
            
            expand_selectors = [
                "//button[contains(@class, 'ExpandableContent')]",
                "//div[contains(@class, 'ExpandableContent')]//button",
                "//button[contains(text(), 'Expand')]",
                "div[class*='ExpandableContent'] button",
                "button[class*='ExpandableContent']"
            ]
            
            all_buttons = []
            
            for selector in expand_selectors:
                try:
                    if selector.startswith("//"):
                        buttons = self.driver.find_elements(By.XPATH, selector)
                    else:
                        buttons = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    
                    for button in buttons:
                        if button.is_displayed() and button.is_enabled():
                            if button not in all_buttons:
                                all_buttons.append(button)
                            
                except Exception as e:
                    logger.debug(f"Erreur avec s√©lecteur {selector}: {e}")
                    continue
            
            logger.debug(f"Trouv√© {len(all_buttons)} boutons Expand au total")
            
            # Si on a au moins 2 boutons, prendre le 2√®me
            if len(all_buttons) >= 2:
                second_button = all_buttons[1]
                logger.debug("‚úÖ Utilisation du 2√®me bouton Expand trouv√©")
                return second_button
            
            # Chercher sp√©cifiquement apr√®s le header "Credits"
            try:
                credits_header = self.driver.find_element(
                    By.XPATH, 
                    "//div[contains(@class, 'SongInfo__Title') and text()='Credits']"
                )
                
                credits_y = credits_header.location['y']
                
                best_button = None
                best_distance = float('inf')
                
                for button in all_buttons:
                    try:
                        button_y = button.location['y']
                        if button_y > credits_y:
                            distance = button_y - credits_y
                            if distance < best_distance and distance < 500:
                                best_distance = distance
                                best_button = button
                    except:
                        continue
                
                if best_button:
                    logger.debug(f"‚úÖ Bouton le plus proche apr√®s Credits s√©lectionn√©")
                    return best_button
                    
            except Exception as e:
                logger.debug(f"Erreur lors de la recherche par position: {e}")
            
            if len(all_buttons) == 1:
                logger.debug("‚ö†Ô∏è Un seul bouton Expand trouv√©, utilisation par d√©faut")
                return all_buttons[0]
            
            logger.debug("‚ùå Aucun bouton Expand Credits appropri√© trouv√©")
            return None
            
        except Exception as e:
            logger.error(f"Erreur lors de la recherche du bouton Expand: {e}")
            return None

    def _extract_header_metadata(self, track: Track):
        """Extrait les m√©tadonn√©es depuis le header de la page - VERSION CORRIG√âE"""
        try:
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            
            # Chercher l'info album dans le header
            album_container = soup.find('div', class_=lambda x: x and 'HeaderCredit__Container' in x)
            
            if album_container:
                # Extraire le num√©ro de piste
                track_label = album_container.find('span', class_=lambda x: x and 'HeaderCredit__Label' in x)
                if track_label:
                    track_text = track_label.get_text(strip=True)
                    # Extraire le num√©ro de la piste (ex: "Track 14 on")
                    track_match = re.search(r'Track (\d+)', track_text)
                    if track_match:
                        track.track_number = int(track_match.group(1))
                        logger.debug(f"üî¢ Num√©ro de piste: {track.track_number}")
                
                # CORRECTION: Extraire l'album avec validation
                album_link = album_container.find('a', class_=lambda x: x and 'StyledLink' in x)
                if album_link and not track.album:  # Ne pas √©craser si d√©j√† d√©fini
                    potential_album = album_link.get_text(strip=True)
                    # Nettoyer le nom (enlever les symboles de fl√®che)
                    potential_album = re.sub(r'\s*[\u2192\u2190\u2191\u2193‚Üí‚Üê‚Üë‚Üì]\s*', '', potential_album).strip()
                    
                    # CORRECTION: V√©rifier que ce n'est pas un nom de producteur
                    # Liste de producteurs connus qui sont souvent confondus avec des albums
                    known_producers = [
                        'easy dew', 'easydew', 'pyroman', 'the beatmaker', 'dj bellek',
                        'mike dean', 'metro boomin', 'pi\'erre bourne', 'wheezy',
                        'southside', 'tm88', 'zaytoven', 'lex luger', 'young chop',
                        'dj mustard', 'hit-boy', 'boi-1da', 'noah shebib', '40',
                        'pharrell', 'the neptunes', 'timbaland', 'dr. dre',
                        'kanye west', 'j dilla', 'madlib', 'alchemist', 'premier'
                    ]
                    
                    # V√©rifier si c'est probablement un producteur
                    is_likely_producer = any(
                        producer.lower() in potential_album.lower() 
                        for producer in known_producers
                    )
                    
                    # V√©rifications suppl√©mentaires pour d√©tecter un producteur
                    producer_indicators = [
                        'prod', 'produced', 'beats', 'beat', 'dj ', 'mc ', 
                        'young ', 'lil ', 'big ', 'the ', '& '
                    ]
                    
                    has_producer_indicators = any(
                        indicator in potential_album.lower() 
                        for indicator in producer_indicators
                    )
                    
                    # Si c'est probablement un producteur, ne pas l'utiliser comme album
                    if is_likely_producer or (has_producer_indicators and len(potential_album) < 30):
                        logger.debug(f"üö´ '{potential_album}' d√©tect√© comme producteur, ignor√© pour l'album")
                    else:
                        track.album = potential_album
                        logger.debug(f"üíø Album extrait du header: {potential_album}")
                        
        except Exception as e:
            logger.debug(f"Erreur lors de l'extraction des m√©tadonn√©es du header: {e}")
            
    def _is_valid_album_name(self, name: str) -> bool:
        """Valide si un nom est bien un album et pas un producteur"""
        
        if not name or len(name.strip()) < 2:
            return False
        
        name_lower = name.lower().strip()
        
        # Liste √©tendue de producteurs connus
        known_producers = [
            'easy dew', 'easydew', 'pyroman', 'the beatmaker', 'dj bellek',
            'mike dean', 'metro boomin', 'pi\'erre bourne', 'wheezy',
            'southside', 'tm88', 'zaytoven', 'lex luger', 'young chop',
            'dj mustard', 'hit-boy', 'boi-1da', 'noah shebib', '40',
            'pharrell', 'the neptunes', 'timbaland', 'dr. dre', 'scott storch',
            'kanye west', 'j dilla', 'madlib', 'alchemist', 'dj premier',
            'cashmoneyap', 'tay keith', 'ronnyj', 'cubeatz', 'murda beatz'
        ]
        
        # V√©rification directe des producteurs connus
        if any(producer in name_lower for producer in known_producers):
            return False
        
        # Indicateurs de producteurs
        producer_indicators = [
            'prod by', 'produced by', 'prod.', 'beats by', 'beat by',
            'dj ', 'mc ', 'young ', 'lil ', 'big ', '$', 
            'beatz', 'beats', 'productions', 'muzik', 'music'
        ]
        
        # Si c'est court ET contient des indicateurs de producteur
        if len(name) < 20 and any(indicator in name_lower for indicator in producer_indicators):
            return False
        
        # Si √ßa commence par des pr√©fixes typiques de producteurs
        producer_prefixes = ['dj ', 'mc ', 'young ', 'lil ', 'big ', 'the ']
        if any(name_lower.startswith(prefix) for prefix in producer_prefixes) and len(name) < 25:
            return False
        
        # Si c'est probablement un album
        album_indicators = [
            'vol', 'volume', 'ep', 'mixtape', 'album', 'deluxe', 
            'edition', 'part', 'chapter', 'saison', 'tome'
        ]
        
        if any(indicator in name_lower for indicator in album_indicators):
            return True
        
        # Si c'est assez long, probablement un album
        if len(name) > 25:
            return True
        
        # Par d√©faut, accepter si pas d'indicateur de producteur
        return True
    
    def _extract_credits(self, track: Track) -> List[Credit]:
        """Extrait les cr√©dits de la page - VERSION AVEC MEILLEURE GESTION ALBUM"""
        credits = []
        
        try:
            time.sleep(1)
            self.wait.until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "div[class*='SongInfo__Credit']"))
            )
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            
            # Parcourir tous les √©l√©ments de cr√©dit
            for credit_element in soup.select("div[class*='SongInfo__Credit']"):
                # Trouver le label (r√¥le)
                label_div = credit_element.find("div", class_=re.compile(r"SongInfo__Label"))
                if not label_div:
                    continue
                    
                role_text = label_div.get_text(strip=True)
                
                # Trouver le conteneur des valeurs (noms)
                container_div = label_div.find_next_sibling("div")
                if not container_div:
                    continue
                
                # Extraire les noms intelligemment
                names = self._extract_names_intelligently(container_div)
                
                # CORRECTION: Gestion am√©lior√©e du cas "album"
                if role_text.lower() == 'album':
                    if names and not track.album:  # Seulement si manquant de l'API
                        potential_album = ' '.join(names)
                        
                        # CORRECTION: Validation am√©lior√©e de l'album
                        # Ne pas accepter si √ßa ressemble trop √† un nom de producteur
                        if self._is_valid_album_name(potential_album):
                            track.album = potential_album
                            logger.debug(f"üíø Album scrap√© et valid√©: {track.album}")
                        else:
                            logger.debug(f"üö´ Album potentiel rejet√© (probablement producteur): {potential_album}")
                    continue
                
                # Traiter les autres cas sp√©ciaux normalement
                elif role_text.lower() == 'released on':
                    if names and not track.release_date:
                        date_text = ' '.join(names)
                        parsed_date = self._parse_release_date(date_text)
                        if parsed_date:
                            track.release_date = parsed_date
                            logger.debug(f"üìÖ Date de sortie scrap√©e: {date_text}")
                    continue
                    
                elif role_text.lower() == 'genre':
                    if names and not track.genre:
                        track.genre = ', '.join(names)
                        logger.debug(f"üéµ Genre scrap√©: {track.genre}")
                    continue
                
                # Cr√©er les objets Credit pour chaque nom
                role_enum = self._map_genius_role_to_enum(role_text)
                if not role_enum:
                    role_enum = CreditRole.OTHER
                
                for name in names:
                    if name and len(name.strip()) > 0:
                        credit = Credit(
                            name=name.strip(),
                            role=role_enum,
                            role_detail=role_text if role_enum == CreditRole.OTHER else None,
                            source="genius"
                        )
                        credits.append(credit)
                        logger.debug(f"Cr√©dit cr√©√©: {name.strip()} - {role_enum.value}")
            
            # D√©doublonner les cr√©dits
            credits = self._deduplicate_credits(credits)
            
            logger.info(f"Extraction termin√©e : {len(credits)} cr√©dits uniques trouv√©s")
            
            # Debug si aucun cr√©dit trouv√©
            if not credits:
                self._debug_no_credits_found(soup)

        except TimeoutException:
            logger.warning("Timeout en attendant les cr√©dits")
        except Exception as e:
            logger.error(f"Erreur lors de l'extraction des cr√©dits: {e}")
            import traceback
            logger.debug(f"Traceback complet: {traceback.format_exc()}")
        
        return credits
    
    def _extract_names_intelligently(self, container_div) -> List[str]:
        """Extrait les noms depuis le conteneur de mani√®re intelligente - M√âTHODE RESTAUR√âE"""
        names = []
        
        try:
            # R√©cup√©rer les noms depuis les liens <a>
            for link in container_div.select("a"):
                name = link.get_text(strip=True)
                if name and name not in names:
                    names.append(name)
            
            # R√©cup√©rer le texte brut (hors liens) et le nettoyer
            for text_node in container_div.find_all(text=True, recursive=False):
                text = text_node.strip()
                if text and text not in names:
                    # S√©parer par diff√©rents d√©limiteurs
                    for separator in [' & ', ', ', ' and ', ' + ', ' / ']:
                        if separator in text:
                            parts = text.split(separator)
                            for part in parts:
                                clean_part = part.strip()
                                if clean_part and clean_part not in names:
                                    names.append(clean_part)
                            break
                    else:
                        # Pas de s√©parateur trouv√©, ajouter le texte tel quel
                        if text not in names:
                            names.append(text)
            
            # Nettoyer les noms (enlever &amp; etc.)
            cleaned_names = []
            for name in names:
                cleaned = name.replace('&amp;', '&').strip()
                if cleaned and len(cleaned) > 1:
                    cleaned_names.append(cleaned)
            
            return cleaned_names
            
        except Exception as e:
            logger.debug(f"Erreur lors de l'extraction intelligente des noms: {e}")
            return []
    
    def _parse_release_date(self, date_text: str) -> Optional[datetime]:
        """Parse une date de sortie depuis le texte"""
        try:
            date_patterns = [
                "%B %d, %Y",      # September 14, 2018
                "%b %d, %Y",      # Sep 14, 2018
                "%Y-%m-%d",       # 2018-09-14
                "%d/%m/%Y",       # 14/09/2018
                "%m/%d/%Y",       # 09/14/2018
                "%Y",             # 2018 (ann√©e seule)
            ]

            date_text = date_text.strip()
            
            for pattern in date_patterns:
                try:
                    return datetime.strptime(date_text, pattern)
                except ValueError:
                    continue
                    
            logger.debug(f"‚ö†Ô∏è Format de date non reconnu: {date_text}")
            return None

        except Exception as e:
            logger.debug(f"Erreur lors du parsing de la date: {e}")
            return None

    def _map_genius_role_to_enum(self, genius_role: str) -> Optional[CreditRole]:
        """Mappe un r√¥le Genius vers notre √©num√©ration"""
        role_mapping = {
            # Production
            'Producer': CreditRole.PRODUCER,
            'Co-Producer': CreditRole.CO_PRODUCER,
            'Executive Producer': CreditRole.EXECUTIVE_PRODUCER,
            'Vocal Producer': CreditRole.VOCAL_PRODUCER,
            'Additional Production': CreditRole.ADDITIONAL_PRODUCTION,
        
            # √âcriture
            'Writer': CreditRole.WRITER,
            'Songwriter': CreditRole.WRITER,
            'Composer': CreditRole.COMPOSER,
            'Lyricist': CreditRole.LYRICIST,
        
            # Studio
            'Mixing Engineer': CreditRole.MIXING_ENGINEER,
            'Mix Engineer': CreditRole.MIXING_ENGINEER,
            'Mastering Engineer': CreditRole.MASTERING_ENGINEER,
            'Recording Engineer': CreditRole.RECORDING_ENGINEER,
            'Engineer': CreditRole.ENGINEER,
        
            # Chant
            'Vocals': CreditRole.VOCALS,
            'Lead Vocals': CreditRole.LEAD_VOCALS,
            'Background Vocals': CreditRole.BACKGROUND_VOCALS,
            'Additional Vocals': CreditRole.ADDITIONAL_VOCALS,
            'Choir': CreditRole.CHOIR,
        
            # Label et √©dition
            'Label': CreditRole.LABEL,
            'Publisher': CreditRole.PUBLISHER,
            'Distributor': CreditRole.DISTRIBUTOR,

            # Instruments
            'Guitar': CreditRole.GUITAR,
            'Bass Guitar': CreditRole.BASS_GUITAR,
            'Acoustic Guitar': CreditRole.ACOUSTIC_GUITAR,
            'Electric Guitar': CreditRole.ELECTRIC_GUITAR,
            'Drums': CreditRole.DRUMS,
            'Piano': CreditRole.PIANO,
            'Keyboard': CreditRole.KEYBOARD,
            'Synthesizer': CreditRole.SYNTHESIZER,
            'Bass': CreditRole.BASS,

            # Artwork
            'Art Direction': CreditRole.ART_DIRECTION,
            'Artwork': CreditRole.ARTWORK,
            'Graphic Design': CreditRole.GRAPHIC_DESIGN,
            'Photography': CreditRole.PHOTOGRAPHY,
            'Illustration': CreditRole.ILLUSTRATION,

            # Cr√©dits vid√©o
            'Video Director': CreditRole.VIDEO_DIRECTOR,
            'Video Producer': CreditRole.VIDEO_PRODUCER,
            'Video Director of Photography': CreditRole.VIDEO_DIRECTOR_OF_PHOTOGRAPHY,
            'Video Cinematographer': CreditRole.VIDEO_CINEMATOGRAPHER,
            'Video Digital Imaging Technician': CreditRole.VIDEO_DIGITAL_IMAGING_TECHNICIAN,
            'Video Camera Operator': CreditRole.VIDEO_CAMERA_OPERATOR,
            'Video Drone Operator': CreditRole.VIDEO_DRONE_OPERATOR,
            'Video Set Decorator': CreditRole.VIDEO_SET_DECORATOR,
            'Video Editor': CreditRole.VIDEO_EDITOR,
            'Video Colorist': CreditRole.VIDEO_COLORIST,

            # Autres
            'Featuring': CreditRole.FEATURED,
            'Sample': CreditRole.SAMPLE,
            'A&R': CreditRole.A_AND_R,
        }
    
        # Recherche exacte d'abord
        if genius_role in role_mapping:
            return role_mapping[genius_role]
    
        # Recherche insensible √† la casse
        genius_role_lower = genius_role.lower()
        for key, value in role_mapping.items():
            if key.lower() == genius_role_lower:
                return value
    
        # Recherche partielle pour les r√¥les complexes
        if 'producer' in genius_role_lower:
            if 'co' in genius_role_lower:
                return CreditRole.CO_PRODUCER
            elif 'executive' in genius_role_lower:
                return CreditRole.EXECUTIVE_PRODUCER
            elif 'vocal' in genius_role_lower:
                return CreditRole.VOCAL_PRODUCER
            else:
                return CreditRole.PRODUCER
    
        if 'engineer' in genius_role_lower:
            if 'mix' in genius_role_lower:
                return CreditRole.MIXING_ENGINEER
            elif 'master' in genius_role_lower:
                return CreditRole.MASTERING_ENGINEER
            elif 'record' in genius_role_lower:
                return CreditRole.RECORDING_ENGINEER
            else:
                return CreditRole.ENGINEER
    
        if 'vocal' in genius_role_lower:
            if 'lead' in genius_role_lower:
                return CreditRole.LEAD_VOCALS
            elif 'background' in genius_role_lower or 'backing' in genius_role_lower:
                return CreditRole.BACKGROUND_VOCALS
            elif 'additional' in genius_role_lower:
                return CreditRole.ADDITIONAL_VOCALS
            else:
                return CreditRole.VOCALS

        if 'guitar' in genius_role_lower:
            if 'bass' in genius_role_lower:
                return CreditRole.BASS_GUITAR
            elif 'acoustic' in genius_role_lower:
                return CreditRole.ACOUSTIC_GUITAR
            elif 'electric' in genius_role_lower:
                return CreditRole.ELECTRIC_GUITAR
            else:
                return CreditRole.GUITAR

        # Gestion sp√©ciale des r√¥les vid√©o
        if 'video' in genius_role_lower:
            if 'director' in genius_role_lower and 'photography' in genius_role_lower:
                return CreditRole.VIDEO_DIRECTOR_OF_PHOTOGRAPHY
            elif 'director' in genius_role_lower:
                return CreditRole.VIDEO_DIRECTOR
            elif 'producer' in genius_role_lower:
                return CreditRole.VIDEO_PRODUCER
            elif 'cinematographer' in genius_role_lower:
                return CreditRole.VIDEO_CINEMATOGRAPHER
            elif 'camera' in genius_role_lower:
                return CreditRole.VIDEO_CAMERA_OPERATOR
            elif 'drone' in genius_role_lower:
                return CreditRole.VIDEO_DRONE_OPERATOR
            elif 'editor' in genius_role_lower:
                return CreditRole.VIDEO_EDITOR
            elif 'colorist' in genius_role_lower:
                return CreditRole.VIDEO_COLORIST
            elif 'set decorator' in genius_role_lower:
                return CreditRole.VIDEO_SET_DECORATOR

        return CreditRole.OTHER

    def _deduplicate_credits(self, credits: List[Credit]) -> List[Credit]:
        """Supprime les doublons de cr√©dits"""
        seen = set()
        unique_credits = []
    
        for credit in credits:
            key = (credit.name.lower().strip(), credit.role.value)
        
            if key not in seen:
                seen.add(key)
                unique_credits.append(credit)
            else:
                logger.debug(f"Doublon ignor√©: {credit.name} - {credit.role.value}")
    
        return unique_credits

    def _debug_no_credits_found(self, soup):
        """Debug quand aucun cr√©dit n'est trouv√©"""
        logger.debug("üîç DEBUG: Aucun cr√©dit trouv√©, analyse de la structure...")

        # Chercher tous les √©l√©ments qui pourraient contenir des cr√©dits
        potential_containers = [
            soup.find_all('div', class_=lambda x: x and 'SongInfo' in x),
            soup.find_all('div', class_=lambda x: x and 'Credit' in x),
            soup.find_all('div', class_=lambda x: x and 'ExpandableContent' in x)
        ]

        for i, containers in enumerate(potential_containers):
            logger.debug(f"M√©thode {i+1}: Trouv√© {len(containers)} √©l√©ments potentiels")
            for j, container in enumerate(containers[:3]):  # Limiter √† 3 pour √©viter le spam
                text = container.get_text(strip=True)[:100]
                classes = container.get('class', [])
                logger.debug(f"  √âl√©ment {j+1}: classes={classes}, texte='{text}...'")

    def get_album_url_from_track(self, track_url: str) -> Optional[str]:
        """R√©cup√®re l'URL de l'album depuis une page de morceau"""
        try:
            self.driver.get(track_url)
            time.sleep(1)
            
            # Chercher le lien vers l'album
            album_link = self.driver.find_element(
                By.XPATH, 
                "//a[contains(@class, 'PrimaryAlbum__Title') or contains(@href, '/albums/')]"
            )
            
            if album_link:
                return album_link.get_attribute('href')
                
        except NoSuchElementException:
            logger.debug("Pas de lien album trouv√©")
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration de l'URL album: {e}")
        
        return None
    
    def scrape_multiple_tracks(self, tracks: List[Track], progress_callback=None) -> Dict[str, Any]:
        """Scrape plusieurs morceaux avec rapport de progression"""
        results = {
            'success': 0,
            'failed': 0,
            'errors': [],
            'albums_scraped': set()
        }
        
        total = len(tracks)
        album_credits_cache = {}
        
        for i, track in enumerate(tracks):
            try:
                logger.info(f"Scraping du morceau {i+1}/{total}: {track.title}")
                
                # Scraper les cr√©dits du morceau
                credits = self.scrape_track_credits(track)
                
                # V√©rifier le succ√®s
                if len(track.credits) > 0:
                    results['success'] += 1
                    logger.info(f"‚úÖ {len(track.credits)} cr√©dits extraits pour {track.title}")
                else:
                    results['failed'] += 1
                    logger.warning(f"‚ùå Aucun cr√©dit extrait pour {track.title}")
                
                # Callback de progression
                if progress_callback:
                    progress_callback(i + 1, total, track.title)
                    
            except Exception as e:
                results['failed'] += 1
                error_msg = f"Erreur sur {track.title}: {str(e)}"
                results['errors'].append({
                    'track': track.title,
                    'error': str(e)
                })
                logger.error(error_msg)
                track.scraping_errors.append(str(e))
        
        logger.info(f"Scraping termin√©: {results['success']} r√©ussis, {results['failed']} √©chou√©s")
        return results
    
    def scrape_track_lyrics(self, track: Track) -> str:
        """Scrape les paroles d'un morceau"""
        if not track.genius_url:
            logger.warning(f"Pas d'URL Genius pour {track.title}")
            return ""

        lyrics = ""

        try:
            logger.info(f"Scraping des paroles pour: {track.title}")
            self.driver.get(track.genius_url)

            # Gestion des cookies (si n√©cessaire)
            try:
                WebDriverWait(self.driver, 5).until(
                    EC.presence_of_element_located((By.ID, "onetrust-banner-sdk"))
                )
                accept_btn = WebDriverWait(self.driver, 5).until(
                    EC.element_to_be_clickable((By.ID, "onetrust-accept-btn-handler"))
                )
                accept_btn.click()
                time.sleep(1)
            except TimeoutException:
                pass

            # Attendre que les paroles se chargent
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "[data-lyrics-container='true']"))
            )

            # R√©cup√©rer les paroles
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            
            # Chercher les conteneurs de paroles
            lyrics_containers = soup.find_all('div', {'data-lyrics-container': 'true'})
            
            if lyrics_containers:
                lyrics_parts = []
                for container in lyrics_containers:
                    # Extraire le texte en pr√©servant les sauts de ligne
                    text = container.get_text(separator='\n', strip=True)
                    if text:
                        lyrics_parts.append(text)
                
                lyrics = '\n\n'.join(lyrics_parts)
                
                # Nettoyer les paroles
                lyrics = self._clean_lyrics(lyrics)
                
                logger.info(f"‚úÖ Paroles r√©cup√©r√©es pour {track.title} ({len(lyrics.split())} mots)")
            else:
                logger.warning(f"‚ö†Ô∏è Conteneur de paroles non trouv√© pour {track.title}")

            # Respecter le rate limit
            time.sleep(DELAY_BETWEEN_REQUESTS)

        except TimeoutException:
            logger.warning(f"Timeout lors du scraping des paroles de {track.title}")
        except Exception as e:
            logger.error(f"Erreur lors du scraping des paroles: {e}")

        return lyrics

    def _clean_lyrics(self, lyrics: str) -> str:
        """Nettoie les paroles en gardant la mise en page originale - VERSION CORRIG√âE"""
        if not lyrics:
            return ""
        
        import re
        
        # 1: Supprimer uniquement les √©l√©ments parasites sp√©cifiques
        
        # Supprimer la section contributors au d√©but
        lyrics = re.sub(r'^.*?Contributors.*?Lyrics\s*', '', lyrics, flags=re.DOTALL | re.MULTILINE)
        
        # Supprimer les sections [Paroles de "titre"] au d√©but
        lyrics = re.sub(r'^\s*\[Paroles de[^\]]*\]\s*', '', lyrics, flags=re.MULTILINE)
        
        # Supprimer "You might also like" et les suggestions
        lyrics = re.sub(r'You might also like.*?(?=\[|$)', '', lyrics, flags=re.DOTALL | re.MULTILINE)
        
        # Supprimer les lignes "123Embed" ou "Embed"
        lyrics = re.sub(r'\n\d*Embed', '', lyrics, flags=re.MULTILINE)
        
        # Supprimer "See [Language] Translations"
        lyrics = re.sub(r'\nSee.*?Translations', '', lyrics, flags=re.MULTILINE)
        
        # 2: CORRECTION - Reconstituer les lignes correctement
        
        lines = lyrics.split('\n')
        cleaned_lines = []
        i = 0
        
        while i < len(lines):
            current_line = lines[i].rstrip()
            
            # Si c'est une ligne vide, la garder
            if not current_line.strip():
                cleaned_lines.append('')
                i += 1
                continue
            
            # V√©rifier si la ligne suivante est une annotation qui doit √™tre rattach√©e
            if i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                
                # Cas 1: Annotations entre parenth√®ses (Yeah), (Fort, fort, mhh), etc.
                if re.match(r'^\([^)]*\)$', next_line):
                    current_line += f" {next_line}"
                    i += 1  # Sauter la ligne suivante car fusionn√©e
                
                # Cas 2: Annotations simples comme "Yeah", "Mhh" seules sur leur ligne
                elif re.match(r'^(Yeah|Mhh|Ahh|Oh|Wow|Ay|Ey|Hum|Hmm|Fort|Oui|Non)$', next_line, re.IGNORECASE):
                    current_line += f" ({next_line})"
                    i += 1  # Sauter la ligne suivante car fusionn√©e
            
            cleaned_lines.append(current_line)
            i += 1
        
        lyrics = '\n'.join(cleaned_lines)
        
        # 3: Nettoyer les espaces et retours √† la ligne excessifs
        
        # R√©duire les retours √† la ligne multiples (plus de 2) √† maximum 2
        lyrics = re.sub(r'\n\s*\n\s*\n+', '\n\n', lyrics)
        
        # Nettoyer les espaces en fin de lignes seulement
        lines = lyrics.split('\n')
        cleaned_lines = [line.rstrip() for line in lines]
        lyrics = '\n'.join(cleaned_lines)
        
        # Supprimer les lignes vides en d√©but et fin
        lyrics = lyrics.strip()
        
        return lyrics

    def scrape_multiple_tracks_with_lyrics(self, tracks: List[Track], progress_callback=None, include_lyrics=True) -> Dict[str, Any]:
        """Scrape plusieurs morceaux avec option paroles - VERSION SIMPLIFI√âE"""
        results = {
            'success': 0,
            'failed': 0,
            'errors': [],
            'albums_scraped': set(),
            'lyrics_scraped': 0
        }
        
        total = len(tracks)
        
        for i, track in enumerate(tracks):
            try:
                logger.info(f"Scraping du morceau {i+1}/{total}: {track.title}")
                
                # Scraper les cr√©dits (m√©thode existante)
                credits = self.scrape_track_credits(track)
                
                # Scraper les paroles si demand√©
                if include_lyrics:
                    try:
                        lyrics = self.scrape_track_lyrics(track)
                        if lyrics:
                            track.lyrics = lyrics
                            track.has_lyrics = True
                            track.lyrics_scraped_at = datetime.now()
                            results['lyrics_scraped'] += 1
                            logger.info(f"‚úÖ Paroles r√©cup√©r√©es pour {track.title}")
                        else:
                            track.has_lyrics = False
                            
                    except Exception as lyrics_error:
                        logger.warning(f"Erreur paroles pour {track.title}: {lyrics_error}")
                        track.has_lyrics = False
                
                # V√©rifier le succ√®s
                if len(track.credits) > 0:
                    results['success'] += 1
                    logger.info(f"‚úÖ {len(track.credits)} cr√©dits extraits pour {track.title}")
                else:
                    results['failed'] += 1
                    logger.warning(f"‚ùå Aucun cr√©dit extrait pour {track.title}")
                
                # Callback de progression
                if progress_callback:
                    status = f"Cr√©dits + paroles: {track.title}" if include_lyrics else f"Cr√©dits: {track.title}"
                    progress_callback(i + 1, total, status)
                    
            except Exception as e:
                results['failed'] += 1
                error_msg = f"Erreur sur {track.title}: {str(e)}"
                results['errors'].append({
                    'track': track.title,
                    'error': str(e)
                })
                logger.error(error_msg)
                track.scraping_errors.append(str(e))
        
        logger.info(f"Scraping termin√©: {results['success']} r√©ussis, {results['failed']} √©chou√©s")
        if include_lyrics:
            logger.info(f"Paroles: {results['lyrics_scraped']} r√©cup√©r√©es")
        
        return results